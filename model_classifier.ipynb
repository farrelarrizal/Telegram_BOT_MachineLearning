{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train'\n",
    "TEST_DIR = 'data/test'\n",
    "VAL_DIR = 'data/val'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 3 classes.\n",
      "Found 624 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                rescale=1/255,\n",
    "                                rotation_range=20,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest'\n",
    "\n",
    "                                   )\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=10,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    color_mode='grayscale')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=10,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    color_mode='grayscale')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# model to predict 3 classes\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 298, 298, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 149, 149, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 73, 73, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 35, 35, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 78400)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               40141312  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,230,659\n",
      "Trainable params: 40,230,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "522/522 [==============================] - 171s 327ms/step - loss: 0.8447 - acc: 0.6198 - val_loss: 0.8238 - val_acc: 0.6330\n",
      "Epoch 2/20\n",
      "522/522 [==============================] - 180s 344ms/step - loss: 0.7228 - acc: 0.6929 - val_loss: 0.7067 - val_acc: 0.7468\n",
      "Epoch 3/20\n",
      "522/522 [==============================] - 178s 341ms/step - loss: 0.6792 - acc: 0.7132 - val_loss: 0.6589 - val_acc: 0.7532\n",
      "Epoch 4/20\n",
      "522/522 [==============================] - 169s 324ms/step - loss: 0.6700 - acc: 0.7189 - val_loss: 0.7007 - val_acc: 0.6571\n",
      "Epoch 5/20\n",
      "522/522 [==============================] - 182s 348ms/step - loss: 0.6439 - acc: 0.7320 - val_loss: 0.7608 - val_acc: 0.7244\n",
      "Epoch 6/20\n",
      "522/522 [==============================] - 169s 325ms/step - loss: 0.6307 - acc: 0.7327 - val_loss: 1.1659 - val_acc: 0.5673\n",
      "Epoch 7/20\n",
      "522/522 [==============================] - 166s 318ms/step - loss: 0.6229 - acc: 0.7372 - val_loss: 0.7291 - val_acc: 0.8061\n",
      "Epoch 8/20\n",
      "522/522 [==============================] - 168s 321ms/step - loss: 0.6057 - acc: 0.7510 - val_loss: 0.8712 - val_acc: 0.7212\n",
      "Epoch 9/20\n",
      "522/522 [==============================] - 176s 338ms/step - loss: 0.5891 - acc: 0.7488 - val_loss: 0.9214 - val_acc: 0.7196\n",
      "Epoch 10/20\n",
      "522/522 [==============================] - 174s 334ms/step - loss: 0.5859 - acc: 0.7517 - val_loss: 0.8571 - val_acc: 0.7596\n",
      "Epoch 11/20\n",
      "522/522 [==============================] - 179s 343ms/step - loss: 0.5691 - acc: 0.7648 - val_loss: 1.3131 - val_acc: 0.6554\n",
      "Epoch 12/20\n",
      "522/522 [==============================] - 186s 357ms/step - loss: 0.5712 - acc: 0.7602 - val_loss: 0.8446 - val_acc: 0.7324\n",
      "Epoch 13/20\n",
      "522/522 [==============================] - 174s 334ms/step - loss: 0.5781 - acc: 0.7538 - val_loss: 0.8181 - val_acc: 0.7388\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1e82675a220>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "          epochs=20,\n",
    "          validation_data=test_generator,\n",
    "          callbacks=[early_stop])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "model.save('model_categorical.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 4s 64ms/step - loss: 0.8181 - acc: 0.7388\n",
      "loss:  0.8181131482124329\n",
      "acc:  0.7387820482254028\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(test_generator)\n",
    "print('loss: ', loss)\n",
    "print('acc: ', acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.engine.sequential.Sequential at 0x1e80f756940>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel/model_categorical.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Institut Teknologi Sepuluh Nopember\\OneDrive - Institut Teknologi Sepuluh Nopember\\Akademik\\Semester 8\\SPK\\code\\venv3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\Institut Teknologi Sepuluh Nopember\\OneDrive - Institut Teknologi Sepuluh Nopember\\Akademik\\Semester 8\\SPK\\code\\venv3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:409\u001B[0m, in \u001B[0;36mConv._get_input_channel\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m    407\u001B[0m channel_axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_channel_axis()\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_shape\u001B[38;5;241m.\u001B[39mdims[channel_axis]\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 409\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe channel dimension of the inputs should be defined. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe input_shape received is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    412\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhere axis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchannel_axis\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (0-based) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis the channel dimension, which found to be `None`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    414\u001B[0m     )\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mint\u001B[39m(input_shape[channel_axis])\n",
      "\u001B[1;31mValueError\u001B[0m: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`."
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model/model_categorical.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img('data/train/PNEUMONIA VIRUS/person86_virus_159.jpeg', target_size=(300,300))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "print(img.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "IMG_PATH = [\n",
    "    'data/test/NORMAL/IM-0033-0001-0002.jpeg',\n",
    "    'data/test/PNEUMONIA BACTERIA/person80_bacteria_389.jpeg'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img_path = 'data/test/PNEUMONIA BACTERIA/person80_bacteria_389.jpeg'\n",
    "img = load_img(img_path, target_size=(300, 300), color_mode='grayscale')\n",
    "\n",
    "# Convert it to a numpy array with target shape\n",
    "img = img_to_array(img)\n",
    "\n",
    "# Rescale by 1/255\n",
    "img = img/255\n",
    "\n",
    "# Add a fourth dimension\n",
    "img = np.expand_dims(img, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.03133188 0.91333777 0.7687464 ]]\n"
     ]
    }
   ],
   "source": [
    "classes = model.predict(img, batch_size=10)\n",
    "print(classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "classes = np.argmax(classes, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1])"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
